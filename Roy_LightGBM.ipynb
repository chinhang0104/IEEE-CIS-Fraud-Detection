{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 86.0245 s\n",
      "File: /workdir/src/features_generation.py\n",
      "Function: feature_engineering at line 221\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   221                                           @profile\n",
      "   222                                           def feature_engineering():\n",
      "   223                                               \"\"\"\n",
      "   224                                               load original datasets and conduct feature engineering\n",
      "   225                                               :return X_train, y_train, X_test, submission:\n",
      "   226                                               \"\"\"\n",
      "   227         1   21810940.0 21810940.0     25.4      train_identity, train_transaction, test_identity, test_transaction, submission = load_data(DATA_DIRECTORY)\n",
      "   228                                           \n",
      "   229         1    6747236.0 6747236.0      7.8      train_identity = id_split(train_identity)\n",
      "   230         1    6811199.0 6811199.0      7.9      test_identity = id_split(test_identity)\n",
      "   231         1    1381993.0 1381993.0      1.6      train = merge_transaction_and_identify(train_transaction, train_identity)\n",
      "   232         1    1305984.0 1305984.0      1.5      test = merge_transaction_and_identify(test_transaction, test_identity)\n",
      "   233                                           \n",
      "   234         1    2092104.0 2092104.0      2.4      train, test = email_mappings(train, test)\n",
      "   235                                           \n",
      "   236         1   14361261.0 14361261.0     16.7      train, test = drop_useless_columns(train, test)\n",
      "   237                                           \n",
      "   238         1         83.0     83.0      0.0      useful_features = recursive_feature_elimination(train)\n",
      "   239                                           \n",
      "   240         1        457.0    457.0      0.0      cols_to_drop = [col for col in train.columns if col not in useful_features]\n",
      "   241         1          4.0      4.0      0.0      cols_to_drop.remove('isFraud')\n",
      "   242         1          1.0      1.0      0.0      cols_to_drop.remove('TransactionDT')\n",
      "   243                                           \n",
      "   244         1     332551.0 332551.0      0.4      train = train.drop(cols_to_drop, axis=1)\n",
      "   245         1     279882.0 279882.0      0.3      test = test.drop(cols_to_drop, axis=1)\n",
      "   246                                           \n",
      "   247         1   29024567.0 29024567.0     33.7      train, test = label_encoding(train, test)\n",
      "   248                                           \n",
      "   249         1     453710.0 453710.0      0.5      X_train = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\n",
      "   250         1     231079.0 231079.0      0.3      y_train = train.sort_values('TransactionDT')['isFraud']\n",
      "   251                                           \n",
      "   252         1     191950.0 191950.0      0.2      X_test = test.drop(['TransactionDT'], axis=1)\n",
      "   253                                           \n",
      "   254         1       3694.0   3694.0      0.0      del train, test\n",
      "   255         1      34755.0  34755.0      0.0      gc.collect()\n",
      "   256                                           \n",
      "   257         1     525381.0 525381.0      0.6      X_train = clean_inf_nan(X_train)\n",
      "   258         1     435693.0 435693.0      0.5      X_test = clean_inf_nan(X_test)\n",
      "   259                                               \n",
      "   260                                               profile.print_stats()\n",
      "   261                                               \n",
      "   262                                               return X_train, y_train, X_test, submission\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "from src.features_generation import feature_engineering\n",
    "\n",
    "X, y, X_test, sample_submission = feature_engineering()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47,\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.948771\tvalid_1's auc: 0.8848\n",
      "[400]\ttraining's auc: 0.969448\tvalid_1's auc: 0.898816\n",
      "[600]\ttraining's auc: 0.982939\tvalid_1's auc: 0.907714\n",
      "[800]\ttraining's auc: 0.989967\tvalid_1's auc: 0.913103\n",
      "[1000]\ttraining's auc: 0.993577\tvalid_1's auc: 0.915619\n",
      "[1200]\ttraining's auc: 0.995713\tvalid_1's auc: 0.916977\n",
      "[1400]\ttraining's auc: 0.996984\tvalid_1's auc: 0.917597\n",
      "[1600]\ttraining's auc: 0.997873\tvalid_1's auc: 0.917664\n",
      "[1800]\ttraining's auc: 0.998451\tvalid_1's auc: 0.91765\n",
      "[2000]\ttraining's auc: 0.998875\tvalid_1's auc: 0.917618\n",
      "[2200]\ttraining's auc: 0.999182\tvalid_1's auc: 0.917413\n",
      "Early stopping, best iteration is:\n",
      "[1763]\ttraining's auc: 0.998357\tvalid_1's auc: 0.917801\n",
      "Fold 1 | AUC: 0.9178013991058426\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.948772\tvalid_1's auc: 0.906949\n",
      "[400]\ttraining's auc: 0.969041\tvalid_1's auc: 0.917841\n",
      "[600]\ttraining's auc: 0.983299\tvalid_1's auc: 0.9264\n",
      "[800]\ttraining's auc: 0.990683\tvalid_1's auc: 0.931045\n",
      "[1000]\ttraining's auc: 0.994345\tvalid_1's auc: 0.93312\n",
      "[1200]\ttraining's auc: 0.996419\tvalid_1's auc: 0.934254\n",
      "[1400]\ttraining's auc: 0.997573\tvalid_1's auc: 0.934514\n",
      "[1600]\ttraining's auc: 0.998322\tvalid_1's auc: 0.93467\n",
      "[1800]\ttraining's auc: 0.998816\tvalid_1's auc: 0.934376\n",
      "[2000]\ttraining's auc: 0.999143\tvalid_1's auc: 0.934042\n",
      "Early stopping, best iteration is:\n",
      "[1662]\ttraining's auc: 0.998489\tvalid_1's auc: 0.934735\n",
      "Fold 2 | AUC: 0.9347348645215919\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.950708\tvalid_1's auc: 0.906011\n",
      "[400]\ttraining's auc: 0.970581\tvalid_1's auc: 0.917866\n",
      "[600]\ttraining's auc: 0.984102\tvalid_1's auc: 0.926766\n",
      "[800]\ttraining's auc: 0.990949\tvalid_1's auc: 0.930387\n",
      "[1000]\ttraining's auc: 0.994498\tvalid_1's auc: 0.931614\n",
      "[1200]\ttraining's auc: 0.996517\tvalid_1's auc: 0.932134\n",
      "[1400]\ttraining's auc: 0.997671\tvalid_1's auc: 0.93209\n",
      "[1600]\ttraining's auc: 0.998423\tvalid_1's auc: 0.931776\n",
      "Early stopping, best iteration is:\n",
      "[1294]\ttraining's auc: 0.997128\tvalid_1's auc: 0.93221\n",
      "Fold 3 | AUC: 0.9322104757340612\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.946879\tvalid_1's auc: 0.919906\n",
      "[400]\ttraining's auc: 0.9682\tvalid_1's auc: 0.933463\n",
      "[600]\ttraining's auc: 0.982986\tvalid_1's auc: 0.943105\n",
      "[800]\ttraining's auc: 0.990401\tvalid_1's auc: 0.947788\n",
      "[1000]\ttraining's auc: 0.994102\tvalid_1's auc: 0.949563\n",
      "[1200]\ttraining's auc: 0.996238\tvalid_1's auc: 0.950234\n",
      "[1400]\ttraining's auc: 0.997464\tvalid_1's auc: 0.950418\n",
      "[1600]\ttraining's auc: 0.998288\tvalid_1's auc: 0.950411\n",
      "[1800]\ttraining's auc: 0.998827\tvalid_1's auc: 0.950064\n",
      "Early stopping, best iteration is:\n",
      "[1447]\ttraining's auc: 0.997685\tvalid_1's auc: 0.95051\n",
      "Fold 4 | AUC: 0.9505102554194065\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.949093\tvalid_1's auc: 0.89961\n",
      "[400]\ttraining's auc: 0.969997\tvalid_1's auc: 0.913017\n",
      "[600]\ttraining's auc: 0.983603\tvalid_1's auc: 0.921258\n",
      "[800]\ttraining's auc: 0.990551\tvalid_1's auc: 0.925014\n",
      "[1000]\ttraining's auc: 0.994148\tvalid_1's auc: 0.92619\n",
      "[1200]\ttraining's auc: 0.996265\tvalid_1's auc: 0.926468\n",
      "[1400]\ttraining's auc: 0.99752\tvalid_1's auc: 0.926338\n",
      "[1600]\ttraining's auc: 0.998298\tvalid_1's auc: 0.925967\n",
      "Early stopping, best iteration is:\n",
      "[1283]\ttraining's auc: 0.99685\tvalid_1's auc: 0.926531\n",
      "Fold 5 | AUC: 0.9265309207221305\n",
      "\n",
      "Mean AUC = 0.9323575831006066\n",
      "Out of folds AUC = 0.9330963387024126\n",
      "CPU times: user 17h 10min 44s, sys: 50.4 s, total: 17h 11min 35s\n",
      "Wall time: 32min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NFOLDS = 5\n",
    "folds = KFold(n_splits=NFOLDS)\n",
    "\n",
    "columns = X.columns\n",
    "splits = folds.split(X, y)\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X.shape[0])\n",
    "score = 0\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = columns\n",
    "  \n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500)\n",
    "    \n",
    "    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n",
    "    \n",
    "    y_pred_valid = clf.predict(X_valid)\n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n",
    "    \n",
    "    score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS\n",
    "    y_preds += clf.predict(X_test) / NFOLDS\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "    gc.collect()\n",
    "    \n",
    "print(f\"\\nMean AUC = {score}\")\n",
    "print(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
